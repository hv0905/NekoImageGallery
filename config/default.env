# This is an example configuration file for the app.
# All the value below are the default values. To change the value, uncomment the line and set the value you want.
# You can also use environment variables or docker secrets to set these values (the key should correspond to the key below).
# Checkout https://docs.pydantic.dev/latest/concepts/pydantic_settings/ for more information.

# ------
# Vector Database Configuration
# ------
# Mode for the vector database, options includes "server" (default), "local" and "memory"
# - server: The preferred mode, uses Qdrant server for vector storage.
# - local: Store vectors as a file on the local disk, this is not recommended for production use (see readme for more information)
# - memory: Uses in-memory storage for vector storage, this is not persistent and should only be used for testing and debugging.
# APP_QDRANT__MODE=server

# Remote Qdrant Server Configuration
# Hostname or IP address of the Qdrant server
# APP_QDRANT__HOST="localhost"
# Port number for the Qdrant HTTP server
# APP_QDRANT__PORT=6333
# Port number for the Qdrant gRPC server
# APP_QDRANT__GRPC_PORT=6334
# Set to True if you want to use gRPC for qdrant connection instead of HTTP
# APP_QDRANT__PREFER_GRPC=True
# Set your API key here if you have set one, otherwise leave it None
# APP_QDRANT__API_KEY=
# Collection name to use in Qdrant
# APP_QDRANT__COLL="NekoImg"

# Local Qdrant File Configuration
# Path to the file where vectors will be stored
# APP_QDRANT__LOCAL_PATH="./images_metadata"


# ------
# Server Configuration
# ------
# Specify device to be used while inferencing vectors by PyTorch. Setting this to "auto" allows the system to automatically detect and use available devices, otherwise specify the device name
# APP_DEVICE="auto"
# List of allowed origins for CORS (Cross-Origin Resource Sharing)
# APP_CORS_ORIGINS=["*"]

# ðŸ’¡ New feature! Set this to True to enable frontend support. This is default to false for backward compatibility.
# Warning: After enabling this, all the api will goes to /api/ path, so you might need to update your API endpoints accordingly if you are using the API directly.
# Hint1: After enabling this, you might have trouble accessing the openapi docs at /docs since the aggressive Service Worker will try to redirect you to the frontend. You can access on incognito browser or disable the Service Worker in the browser devtools.
# Hint2: If you are just changing this option from True to False, you might need to uninstall the Service Worker in your browser since the reason above.
# APP_WITH_FRONTEND=False


# ------
# Models Configuration
# ------
# Model used for CLIP embeddings (Vision Search), accepts both huggingface hub (transformers) model name and path to the model.
# APP_MODEL__CLIP="openai/clip-vit-large-patch14"
# Model used for BERT embeddings (OCR Search), accepts both huggingface hub (transformers) model name and path to the model.
# APP_MODEL__BERT="bert-base-chinese"
# Model used for easypaddocr inference (OCR indexing), accepts path to the model. Leave it blank will download automatically from huggingface hub.
# APP_MODEL__EASYPADDLEOCR=""


# ------
# OCR Search Configuration
# ------
# Enable OCR search functionality
# APP_OCR_SEARCH__ENABLE=True
# OCR module to use for text extraction
# APP_OCR_SEARCH__OCR_MODULE="easypaddleocr"
# Minimum confidence level required for OCR results to be considered
# APP_OCR_SEARCH__OCR_MIN_CONFIDENCE=1e-2
# List of languages supported by the OCR module
# APP_OCR_SEARCH__OCR_LANGUAGE=["ch_sim", "en"]


# ------
# Admin API Configuration
# ------
# Set to True to enable admin API, this allows you to access the admin API using the token specified below.
# APP_ADMIN_API_ENABLE=False
# Uncomment the line below if you enabled admin API. Use this token to access admin API. For security reasons, the admin token is always required if you want to use admin API.
# APP_ADMIN_TOKEN="your-super-secret-admin-token"
# Max length of the upload queue for admin API, higher value means more indexing requests can be queued but also means more memory usage. Upload requests will be blocked when the queue is full.
# APP_ADMIN_INDEX_QUEUE_MAX_LENGTH=200


# ------
# Access Protection Configuration
# ------
# Set to True to enable access protection using tokens
# APP_ACCESS_PROTECTED=False
# Use this token to access the API. This is required if you enabled access protection.
# APP_ACCESS_TOKEN="your-super-secret-access-token"


# ------
# Storage Settings
# ------
# Method for storing files, options includes "local", "s3" and "disabled"
# APP_STORAGE__METHOD="local"

# Storage Settings - local
# Path where files will be stored locally
# APP_STORAGE__LOCAL__PATH="./static"

# Storage Settings - S3
# Name of the S3 bucket
# APP_STORAGE__S3__BUCKET="your-s3-bucket-name"
# Path where files will be stored in the S3 bucket
# APP_STORAGE__S3__PATH="./static"
# Region where the S3 bucket is located
# APP_STORAGE__S3__REGION="your-s3-region"
# Endpoint URL for the S3 service
# APP_STORAGE__S3__ENDPOINT_URL="your-s3-endpoint-url"
# Access key ID for accessing the S3 bucket
# APP_STORAGE__S3__ACCESS_KEY_ID="your-s3-access-key-id"
# Secret access key for accessing the S3 bucket
# APP_STORAGE__S3__SECRET_ACCESS_KEY="your-s3-secret-access-key"
# Session token for accessing the S3 bucket (optional)
# APP_STORAGE__S3__SESSION_TOKEN="your-s3-session-token"
# Optional Endpoint URL for final presentation to the user
# APP_STORAGE__S3__USER_ENDPOINT_URL="your-s3-user-endpoint-url"
